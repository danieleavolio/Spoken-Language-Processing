1. 128 Samples vs 1024 samples | 128 wideband
2. Transfer function LTI discrete time | Rational function
3. Rythm stress intonation | Melody and timing of speech
4. Length of impulse response low pass filter | Infinitely long
5. 10^4 and m = 50 autocorrelation | 200Hz fund freq
6. Mel and linear difference | mel is non linear-perceived fre and linear is linear-phisycal freq
7. Breathy voice | weak and whispery
8. singal 102400 samples, window 1024 samples hop length 128 | 102400-1024/128 + 1 =793
9. 6 multihead 2 attention head, how many attention weights for 10 elems | 6*2*10  
10. Verification task | speech sample and check if identity is correct
11. False MLP claim | MLP is a generative model used for speech
12. Difference between encoder decoder transformer | encoder uses bidirectional attention, decoder use masked causal attention
13. Calculations for attentions | check the first element and then remember the softmax
14. Order delta features | dimension + 1 if first order, +2 if second order (N,2D) or (N,3D)
15. Many to one transformer architecture | audio spectrogram transformer
16. Self supervised learning statement | unlabelled data is used to train a general purpose speech model
17. ASR system for european portoguese, first feature to consider | Mel frequency cepstral coefficients
18. GMM is a | generative model
19. Which features are not used in speech classification | Context dependent features
20. Which parts are calculated in the transformer with linear projection | Query, Key, Value
21. Transformer encoder 6 multihead, 128 input dim, if we have 4 head what dimension is the output | 128/4 = 32
22. What the whisper model cannot do | speech enhancement
23. Why transformer encoder models like discretebert use masked position with expanded spans | avoid exploring local smoothness
24. WaveNet autoregressiv model uses | dilated convolutions layers
25. When ASR is used to perform forced alignment what is not used | the language model
26. LVCSR Conventional Hierarchical large vocabulary continuous speech recognition, what is a model that is not used? | Semantic Model
27. Why LLM are good for task oriented dialog systems | Unificate chic chat and task oriented dialog
28. CTC loss to seq2seq is good because | enforces monotonic attention alignment
29. Dictionary in grapheme to phoneme conversion needs character-to-sound correspondences for what | common words in the language whose pronunciation cannot be predicted
30. BertSCORE, the metric what is true? | It depends on groundh truth to evaluate language generation
31. Describe the x-vector model and architecture, main characteristic, train and what is better respect the previous models and how can you use it for language identification | x-vector model is  DNN used for speaker identification and trained with back propagation. Input are frame level features and there is a pooling layer that collapse everything in a isngle vector. The embedding compress speaker information into a single vector. Advantages is that uses discriminative deep learning. The embeddings can be used for language identification by training a classifier on top of the embeddings.
32. Consider the use of LLM for e2e task for dialogue systems. Explain the general working of the systems and compare to modular task oriented systems | dialogue systems rely on large language models relying on textual prompt to formulate a subtask. The system use the dialogue history and mimics the input and output of the modules of a modular system. The main difference is that the LLM is trained on a large corpus and can generate text that is coherent and fluent. The modular system uses different modules for different tasks and the output is generated by the modules.
33. What distinguishes feature of fricative consonants | turbolent airflow through a narrow constriction
34. Difference between vowel and consonant | consonant has a constriction in the vocal tract anbd vowel uses open vocal tract
35. Organs of the phonatory system | Lanrynx, vocal fodls glottis
36. Transfer function of an LTI system | z transform of the output signal divided by z transform of the input signal
37. Q(z) is called what? | Poles of the transfer function
38. P(z) is called what? | Zeros of the transfer function
39. Overlap algorithm over signal of 101 frames with window length of 512 and hop length of 256 | (100-1)*256+512 = 26112
40. In source filter model the train is used to model what | Filter excitation for voiced phonation
41. Application of linear prediction in speech signal processing | Estimate the spectral envelope of speech signal
42. 2 words with same spelling but diffent pronunciation | homographs and non homophones
43. What we use the Griffin Lim algorithm for | Estimat original phase information based from magnitude spectrum
44. GMM of 16 mixtures, model trained on MFCC of dim 5. Model total parameters | 16*5*2+16 = 176
45. (N,D) adding double delta features | (N,3D)
46. Feature extraction with windows 40ms and 20ms hop size. For 4s signal how many frames | 4/0.02 = 200
47. Why we use DCT in MFCC extraction | to decorrelate and separate low fast varying contributions of spectrum envelope
48. Feature extraction for speech classification which category is not used for type of information | Global
49. GMM UBM is GMM Universal Background Model, used a background model for each characteristic of the speaker. What is something that is not an advantage? | It keeps mean parameters unchanged
50. In hybrid HMM/DNN system for ASR what is a correct thing | transition probabilities are provided by conventional trained HMM/GMM system
51. In LVCSR what components is not a common module | Speaker model
52. WER on phrases is | total number of insertions, deletions and substitutions divided by the number of words in the reference
53. CTC alignment with the null token what is incorrent | the one that continues the previous token after the null token
54. In original transformer what is not calculated as learned parameter? | Positional embedding
55. Which architectures does not support ASR? | VALL-E, it's for tts
56. In encoder decoder vs encoder only what is not shared | Cross attention to consider context
57. In modular task oriented dialogue system what is not part of the language understaning module | dialogue state tracking
58. What is false about OpenAi Whisper | system predict the speaker identity with a specific token
59. What is an advantage of bert over bleu | consider semantic comparison instead of n-gram overlap
60. What is wrong about Sparrow? | System interacts with external tools and db
61. Explain the history of ASR and the final 2 current modern approaches | Initially everything was analogic. Then the most important step was the introduction of HMM and GMM. This was like this until the reag of deep learning. The first step was the introduction of DNN and then the introduction of RNN and LSTM. The final step was the introduction of transformer architecture. Nowadays attention encoder decoder approach is used for ASR but still HMM with DNN as acoustic model is used.
62. What is BLEU metric and what are the problems and limitation. | BLEU ios used to compare generated text to a groundh truth. The problem is that it is based on n-gram overlap and does not consider semantic similarity. It's better to use other metrics like BertSCORE that is based always on ground truth but consider semantic similarity.
63. What describes a prosody unit in speech | unit of speech that is 1 or mor words marked with pauses or changes in pitch
64. Where is LOWEST F0? | Vocal fry
65. Difference between intensity and loudness | intensity is physical and loudness is perceived
66. Difference between DFS and DTFT | DFS is computed on a finite set of freqs and DTFT is computed over all freqs
67. Number of unique values of DFT for seq of rea values N = 1024? | 513 because: N/2 + 1
68. In source filter model, filter is use to model what | spectral envelope of speech sounds
69.  Signal 25600 samples, 512 window and 64 hop size, we want 400 frames for zero padding | 399*64+512 - 25600 = 448
70.  Train a ASR for portoguese, what is the last feature to consider | Prosodic or pitch features
71.  Statement true for self supervised learning |  In fine tuning, labeled data is used to fine tune a general purpose model to obtain a task specific model
72.  Feature extraction for speech classification, which region of analysis is not used | Invariant
73.  Having x vector extractor for MFCC of 40 dimensions as input and hop size 10ms. If we compute 10s of audio signal the output size is | single vector of dimension of the embedding layer of the x-vector model
74.  SVM what type of model | Discriminative model
75.  What do we use OpenSmile for | Extract features for paralinguistic classification tasks
76.  Transformer encoder, 4 multihead and 2 attention heads. how may q,k,v vector are produced for input 20 | 4*2*20*3 = 480
77.  Which part of self attention is used to calculate the attention weights | Query, Key
78.  Why in trasnformer encoder we add or concatenate encodings to input | dot product self attention op are agnostic to ordering the input sequence
79.  SpeechT5 vs Whisper, what differs | one model can produce multi modal output
80.  wav2vec and wav2vec 2.0, what is the idea behind the contrastive predictive codning in the pre training | distinguish correct representation from a set of distractors
81.  What is false about n-grams | produce syntactically correct sentences
82.  HMM are used in ASR for what | Acoustic modeling
83.  In HMM/DNN what does the DNN requiores | DNN requires frame level alignment between audio and recognition units
84.  Advantage of HifiGAn over WaveNet | quality versus latentcy tradeoff
85.  How many non-standard words has the sentence: “João paid 2 euros for the ice cream (a bargain!)”? | 1, the word 2
86.  In task oriented system what is typical | interaction with external tools and databases
87.  What is not part of modular task oriented dialogue system  | question answering
88.  BLEU and BertScore, what is correct about the learn | No metrics are learned from supervised sample
89.  Consider the speech classification pipeline, describe the baseline and feeature extraction, what kinf of model si used and how is trained, how to use for language identification and adv and disadv | Initially Feature extraction bnased on MFCC and then a GMM for each target langauge. It's possible to do post processing with dynamic feature, delta and double delta , silence frame removal. For calssification a GMM is used with the likelihood of the features. Limitation is that we handle only acoustic information and modeling is frame based and models are generative.
90.  What is Sparrow for conversational q&a, the architecture and explain the difference beteween normal question answering system | Sparrow is a conversational q&a model fine tuned with reinforced learning with human feedback. It's based on a trained with following a specific set of rules and with the human feedback based on the answers. System can access internet for evidence and indicating the source. Our LAB3 is a normal question answering system that uses ASR and TTS to answer questions and is based on prompting strategies with small LLM.
91.  Why are decibels typically utilized to depict the intensity of sound as humans perceive it? | More closely matches human perception of loudness
92.  Which of the following phones is an unvoiced dental plosive? | /t/
93.  What common phonetic features do the consonants /f/ and /v/ share? | Both are labiodental fricatives
94.  What is the primary reason for employing short-time processing in speech signals? | to analyze and understand the time-varying properties of speech signals
95.  What conditions must a continuous-time signal meet to be accurately reconstructed from a sequence of samples taken at a rate of 2000 samples per second? | The signal must be bandlimited to 1000 Hz or less
96.  Which of the following statements best describes the relationship between the DTFT and the DFT? | DFT is a sampled version of the DTFT
97.  How is the vowel /a/ classified in terms of place of articulation? | Front
98.  What is the primary difference between the rectangular window and the Hann window used in digital signal processing? | The rectangular window produces more spectral leakage than the Hann window.
99.  In a transition from an unvoiced to a voiced phonation |  the zero-crossing rate decreases
100. What is the main difference between the mel-frequency spectrum and the mel-frequency cepstrum in speech processing? | The mel-frequency spectrum is calculated without using an inverse transform, while the mel-frequency cepstrum requires the use of an inverse transform.
101. What is the relation between the autocorrelation function and the fundamental frequency of a signal? | The autocorrelation function has a maximum at the inverse of the fundamental frequency.
102. Can you explain the primary benefit and the main drawback of employing a longer window in the short-time Fourier transform? | The primary benefit is improved frequency resolution and the main drawback is reduced temporal resolution.
103. What characterizes the transfer function of a discrete-time causal LTI system described by a difference equation? | Quoetient of polynomials
104. What is a formant, and how does it relate to the vocal tract? | A formant is a resonant frequency of the vocal tract, which is determined by the shape and length of the vocal tract.
105. Why is the Linear Prediction (LPC) filter used to model the vocal tract? |  LPC filter is used to model the vocal tract because it can represent its resonant frequencies.
106. Which of the following is a common application of linear prediction in speech signal processing? | Estimating the spectral envelope of a speech signal
107. What characterizes a causal system? | System that depends only on current and past inputs
108. In the source-filter model with a voice-unvoiced switch, what type of excitation is used to model unvoiced fricatives? | White noise
109. What is the discrete-time equivalent of a continuous-time differential equation? | Difference equation
110. Regarding HuBERT and wav2vec2 what is true? | Different pre-training task
111. In speaker verification (SV), the equal error rate of an SV system corresponds to what | The point where the false acceptance rate and false rejection rate are equal
112. The "simple" classification task described in class is characterized in terms of its inputs and outputs because | input sequential and output is one class
113. First-order delta features that are typically appended to MFCCs in feature extraction pipelines are an approximation to the: | velocity of the spectral envelope
114. Second-order delta features that are typically appended to MFCCs in feature extraction pipelines are an approximation to the: | acceleration of the spectral envelope
115. Which of the following features is commonly used by therapists and phoneticians to evaluate voice quality | jitter
116. Which of the following is *not* a typical data augmentation approach used in speech classification tasks? | Remove reverb
117. WER is the metric used for Automatic Speech Recognition evaluation. WER values: | 0-infinite
118. Regarding hybrid HMM/DNN systems for automatic speech recognition, the main difference with previous HMM/GMM systems is that: | DNNs are used to estimate the observation probs
119. Which one of the following, does not correspond to one of the models that is part of a conventional (hierarchical) ASR system? | Prosodic model
120. In large vocabulary continuous speech recognition systems (LVCSR), the name triphone refers to: | The recognition unit that consists of a phoneme and its left and right context 
121. Modern Transformers, e.g. as used in LLMs, consider several optimizations over the original architecture. Which of the following optimizations ARE NOT commonly used? | Can combine masked and bidirectional self-attention in different input parts (i.e., the PrefixLM attention pattern).
122. Consider the problem of Automated Speech Recognition (ASR) with Transformers. Which of the following statements is FALSE? |  The speech features used as input for ASR do not require position embeddings when used with Transformers
123. Considering the SpeechGPT model, which statements is FALSE |  The model bridges a speech encoder and a pre-trained large language model through linear projections.
124. Consider the connectionist temporal classification loss. Which statements is TRUE: | It can be used for training Transformer encoders that map input sequences to output sequences with a different length.
125. Considering the OpenAI Whisper architecture, which of the following tasks IS NOT adequately handled by this model | tts
126. In concatenative speech synthesis which are the costs that should be considered in the unit selection procedure? |  Selection and concatenation costs
127. Consider the contrastive predictive coding objective from wav2vec. Which statements is true? | It is used for self-supervised representation learning, aiming at transfer learning to tasks like speech recognition.
128. Which of these methods for evaluating TTS systems is a subjective test? | MOS
129. What is LAMBDA in synth speech | the model
130. Which of the following components can be a part of the front end of a text-to-speech system? | Normalization, pos tag, grapheme to phoneme (G2P)
131. Which of these is not a speech synthesis method | Mel Cepstrum speech synthesis
132. In speech synthesis, the vocoder is the module responsible for | converting acoustic features into speech waveform
133. Which of the following components are typically NOT INCLUDED in prompts for interacting with large language models.? | Tokens indicating use of external tools
134. Consider modular task-oriented dialogue systems. Which of the following tasks are typically NOT part of natural language understanding modules? | Dialogue state tracking
135. Consider the Few-Shot Bot (FSB) system that was introduced in the classes. Which statement is WRONG? | FSB uses LLM prompts that reflect sub-tasks of modular task-oriented dialogue systems
136. Consider the BERTScore metric for evaluating language generation. Which statement is TRUE? | BERTScore is a metric that is based on the ground truth to evaluate language generation
137. Which of the following is an advantage in the use of large language models for developing task-oriented dialogue systems? | Ease the unification of chit-chat and task-oriented dialogue, leading to more natural conversations
138. Consider chit-chat versus task-oriented dialogue systems. Which of the following statements is more characteristic of task-oriented systems? | System involves interaction with external tools